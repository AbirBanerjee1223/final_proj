{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb26fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: bio in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: networkx in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (3.5)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: biopython>=1.80 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (1.86)\n",
      "Requirement already satisfied: gprofiler-official in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (1.0.0)\n",
      "Requirement already satisfied: mygene in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (3.2.2)\n",
      "Requirement already satisfied: pooch in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (1.8.2)\n",
      "Requirement already satisfied: requests in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (2.32.5)\n",
      "Requirement already satisfied: tqdm in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from bio) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from mygene->bio) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.22.0 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from biothings-client>=0.2.6->mygene->bio) (0.28.1)\n",
      "Requirement already satisfied: anyio in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->bio) (1.3.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from pooch->bio) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from pooch->bio) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from requests->bio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from requests->bio) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\python_progs\\final_year_proj\\.venv\\lib\\site-packages (from tqdm->bio) (0.4.6)\n",
      "Downloading scipy-1.16.3-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.5 MB 3.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.0/38.5 MB 3.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.8/38.5 MB 3.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.6/38.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.7/38.5 MB 3.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.5/38.5 MB 3.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.5/38.5 MB 3.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 6.8/38.5 MB 4.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 7.9/38.5 MB 4.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.9/38.5 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 4.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 11.0/38.5 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.3/38.5 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 13.4/38.5 MB 4.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 13.9/38.5 MB 4.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 14.4/38.5 MB 4.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.2/38.5 MB 4.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.7/38.5 MB 4.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 16.3/38.5 MB 4.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 16.8/38.5 MB 4.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 17.0/38.5 MB 4.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 17.6/38.5 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.4/38.5 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 19.1/38.5 MB 3.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 19.9/38.5 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 21.0/38.5 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 22.0/38.5 MB 3.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 22.5/38.5 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 23.3/38.5 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.1/38.5 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.6/38.5 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.9/38.5 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 25.7/38.5 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 26.7/38.5 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.3/38.5 MB 3.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.6/38.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.4/38.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 30.7/38.5 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.7/38.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.8/38.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.6/38.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.3/38.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 35.7/38.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.7/38.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.16.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy bio networkx scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d619b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ca2a7",
   "metadata": {},
   "source": [
    "## PPI Interaction Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f61066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "data_ppi=pd.read_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\ppi_initial.csv\")\n",
    "\n",
    "# Filter out rows that have no interaction data\n",
    "data_interactions = data_ppi.dropna(subset=['Interacts with']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90adff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Edge Explosion Function\n",
    "def explode_interactions(row):\n",
    "    protein_a = row['Entry']\n",
    "    interactors = row['Interacts with'].split('; ')\n",
    "    \n",
    "    edges = []\n",
    "    for interactor in interactors:\n",
    "        clean_interactor = interactor.strip()        \n",
    "        if clean_interactor:\n",
    "            edges.append((protein_a, clean_interactor))            \n",
    "    return edges\n",
    "\n",
    "# Apply the function to all rows to generate the list of all edges\n",
    "all_edges = data_interactions.apply(explode_interactions, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae01792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Edge List DataFrame\n",
    "ppi_df = pd.DataFrame(all_edges, columns=['Protein_A_Entry', 'Protein_B_Entry'])\n",
    "\n",
    "#Removing Self-Loops\n",
    "ppi_df = ppi_df[ppi_df['Protein_A_Entry'] != ppi_df['Protein_B_Entry']]\n",
    "\n",
    "#Remove Duplicate/Reciprocal Edges\n",
    "ppi_df['Interaction'] = np.minimum(ppi_df['Protein_A_Entry'], ppi_df['Protein_B_Entry']) + \\\n",
    "                       '_' + np.maximum(ppi_df['Protein_A_Entry'], ppi_df['Protein_B_Entry'])\n",
    "\n",
    "#Droping duplicates based on the unique ID, keeping only one entry per unique interaction\n",
    "ppi_df = ppi_df.drop_duplicates(subset=['Interaction']).drop(columns=['Interaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e903504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\abirb\\AppData\\Local\\Temp\\ipykernel_9648\\2843098836.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  output_file = 'D:\\python_progs\\Final_year_proj\\Datasets\\ppi_network_edges.csv'\n"
     ]
    }
   ],
   "source": [
    "#Saving the Final Network Edge List\n",
    "output_file = 'D:\\python_progs\\Final_year_proj\\Datasets\\ppi_network_edges.csv'\n",
    "ppi_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e412249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 109217 interactions from D:\\\\python_progs\\\\Final_year_proj\\Datasets\\\\ppi_network_edges.csv\n",
      "Graph built: 18227 proteins, 109217 interactions\n",
      "Computing centrality measures...\n",
      "Centrality measures computed successfully.\n",
      "Results saved to: D:\\\\python_progs\\\\Final_year_proj\\Datasets\\\\ppi_centrality.csv\n"
     ]
    }
   ],
   "source": [
    "def read_edge_list(path, src_col=\"Protein_A_Entry\", dst_col=\"Protein_B_Entry\"):\n",
    "    df = pd.read_csv(path)\n",
    "    if src_col not in df.columns or dst_col not in df.columns:\n",
    "        raise ValueError(f\"Input CSV must contain '{src_col}' and '{dst_col}' columns.\")\n",
    "    \n",
    "    df = df[[src_col, dst_col]].dropna()\n",
    "    df = df[df[src_col] != df[dst_col]]  # remove self-loops\n",
    "    print(f\"Loaded {len(df)} interactions from {path}\")\n",
    "    return df\n",
    "\n",
    "#Building the PPI graph\n",
    "def build_graph(edges_df, undirected=True):\n",
    "    if undirected:\n",
    "        G = nx.from_pandas_edgelist(edges_df, source=edges_df.columns[0], target=edges_df.columns[1])\n",
    "    else:\n",
    "        G = nx.from_pandas_edgelist(edges_df, source=edges_df.columns[0], target=edges_df.columns[1], create_using=nx.DiGraph)\n",
    "    \n",
    "    print(f\"Graph built: {G.number_of_nodes()} proteins, {G.number_of_edges()} interactions\")\n",
    "    return G\n",
    "\n",
    "#Computing centrality measures\n",
    "def compute_centralities(G):\n",
    "    print(\"Computing centrality measures...\")\n",
    "\n",
    "    degree = dict(G.degree())\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    closeness = nx.closeness_centrality(G)\n",
    "    eigenvector = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    pagerank = nx.pagerank(G)\n",
    "    clustering = nx.clustering(G)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Protein\": list(G.nodes()),\n",
    "        \"Degree\": pd.Series(degree),\n",
    "        \"Degree_Centrality\": pd.Series(degree_centrality),\n",
    "        \"Betweenness_Centrality\": pd.Series(betweenness),\n",
    "        \"Closeness_Centrality\": pd.Series(closeness),\n",
    "        \"Eigenvector_Centrality\": pd.Series(eigenvector)\n",
    "    })\n",
    "\n",
    "    print(\"Centrality measures computed successfully.\")\n",
    "    return df\n",
    "\n",
    "#Saving results to CSV\n",
    "def save_results(df, output_path=\"./ppi_centrality_results.csv\"):\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    input_path = r\"D:\\\\python_progs\\\\Final_year_proj\\Datasets\\\\ppi_network_edges.csv\"  \n",
    "    output_path = r\"D:\\\\python_progs\\\\Final_year_proj\\Datasets\\\\ppi_centrality.csv\"\n",
    "\n",
    "    edges_df = read_edge_list(input_path)\n",
    "    G = build_graph(edges_df)\n",
    "    centrality_df = compute_centralities(G)\n",
    "    save_results(centrality_df, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97693c2",
   "metadata": {},
   "source": [
    "## Physicochemical Features and Shanon Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f9c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aliphatic_index(sequence):\n",
    "    amino_acids = Counter(sequence)\n",
    "    A = amino_acids.get('A', 0)\n",
    "    V = amino_acids.get('V', 0)\n",
    "    I = amino_acids.get('I', 0)\n",
    "    L = amino_acids.get('L', 0)\n",
    "    total_residues = sum(amino_acids.values())\n",
    "\n",
    "    if total_residues == 0:\n",
    "        return 0.0\n",
    "\n",
    "    index = 100 * (A/total_residues + 2.9 * (V/total_residues) + 3.9 * ((I + L)/total_residues))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b657fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\abirb\\AppData\\Local\\Temp\\ipykernel_21632\\1810041501.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_features = pd.read_csv(\"D:\\python_progs\\Final_year_proj\\Datasets\\seq.csv\")\n"
     ]
    }
   ],
   "source": [
    "data_features = pd.read_csv(\"D:\\python_progs\\Final_year_proj\\Datasets\\seq.csv\")\n",
    "\n",
    "features_to_calculate = [\n",
    "    \"Molecular_Weight\", \"Isoelectric_Point\", \"Aromaticity\",\n",
    "    \"Instability_Index\", \"Aliphatic_Index\", \"Net_Charge_pH7\",\n",
    "    \"Hydrophobicity_GRAVY\", \"Positive_Residues\", \"Negative_Residues\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820c3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in features_to_calculate:\n",
    "    data_features[col] = None\n",
    "\n",
    "valid_amino_acids = set(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "skipped_rows = 0\n",
    "\n",
    "for i, row in data_features.iterrows():\n",
    "    raw_seq = str(row[\"Sequence\"])\n",
    "    \n",
    "    try:\n",
    "        sequence = raw_seq.upper().replace(\" \", \"\")\n",
    "        sequence = sequence.replace(\"B\", \"N\").replace(\"Z\", \"Q\").replace(\"X\", \"\")\n",
    "        sequence = \"\".join([aa for aa in sequence if aa in valid_amino_acids])\n",
    "\n",
    "        if len(sequence) == 0:\n",
    "            print(f\"Warning: Row {i} has an empty or invalid sequence after filtering. Skipping calculation.\")\n",
    "            data_features.loc[i, \"Molecular_Weight\"] = 'N/A'\n",
    "            skipped_rows += 1\n",
    "            continue\n",
    "\n",
    "        analysis = ProteinAnalysis(sequence)\n",
    "\n",
    "        data_features.loc[i, \"Molecular_Weight\"] = analysis.molecular_weight()\n",
    "        data_features.loc[i, \"Isoelectric_Point\"] = analysis.isoelectric_point()\n",
    "        data_features.loc[i, \"Aromaticity\"] = analysis.aromaticity()\n",
    "        data_features.loc[i, \"Instability_Index\"] = analysis.instability_index()\n",
    "        data_features.loc[i, \"Aliphatic_Index\"] = calculate_aliphatic_index(sequence)\n",
    "        data_features.loc[i, \"Net_Charge_pH7\"] = analysis.charge_at_pH(7.0)\n",
    "        data_features.loc[i, \"Hydrophobicity_GRAVY\"] = analysis.gravy()\n",
    "\n",
    "        amino_acid_counts = Counter(sequence)\n",
    "        data_features.loc[i, \"Positive_Residues\"] = amino_acid_counts.get(\"K\", 0) + amino_acid_counts.get(\"R\", 0) + amino_acid_counts.get(\"H\", 0)\n",
    "        data_features.loc[i, \"Negative_Residues\"] = amino_acid_counts.get(\"D\", 0) + amino_acid_counts.get(\"E\", 0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Processing Error at row {i} (Sequence: {raw_seq[:30]}...): {e}\")\n",
    "        data_features.loc[i, \"Molecular_Weight\"] = 'ERROR'\n",
    "        skipped_rows += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65342943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\abirb\\AppData\\Local\\Temp\\ipykernel_21632\\1251330302.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  output_file = \"D:\\python_progs\\Final_year_proj\\Datasets\\protein_physicochemical_features_report.csv\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Calculation Summary ---\n",
      "Feature calculation completed.\n",
      "Total input rows: 20420\n",
      "Rows successfully processed: 20420\n",
      "Rows skipped or with errors: 0\n"
     ]
    }
   ],
   "source": [
    "output_file = \"D:\\python_progs\\Final_year_proj\\Datasets\\protein_physicochemical_features_report.csv\"\n",
    "data_features.to_csv(output_file, index=False)\n",
    "\n",
    "rows_processed = len(data_features) - skipped_rows\n",
    "\n",
    "print(\"\\n--- Feature Calculation Summary ---\")\n",
    "print(f\"Feature calculation completed.\")\n",
    "print(f\"Total input rows: {len(data_features)}\")\n",
    "print(f\"Rows successfully processed: {rows_processed}\")\n",
    "print(f\"Rows skipped or with errors: {skipped_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d68eb",
   "metadata": {},
   "source": [
    "## Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab74d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your two feature files\n",
    "df_features = pd.read_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\protein_physicochemical_features_report.csv\") \n",
    "df_ppi = pd.read_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\ppi_centrality.csv\")\n",
    "\n",
    "# Mapping the key\n",
    "df_features.rename(columns={'Entry': 'Protein'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e914bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature rows: 20420\n",
      "Final combined rows:   20420\n"
     ]
    }
   ],
   "source": [
    "# Perform a LEFT merge\n",
    "df_combined = pd.merge(df_features, df_ppi, on='Protein', how='left')\n",
    "\n",
    "ppi_column_names = [col for col in df_ppi.columns if col != 'Protein']\n",
    "\n",
    "# Fill all 'NaN' values in the PPI columns with 0.\n",
    "df_combined[ppi_column_names] = df_combined[ppi_column_names].fillna(0)\n",
    "\n",
    "\n",
    "print(f\"Original feature rows: {len(df_features)}\")\n",
    "print(f\"Final combined rows:   {len(df_combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5b9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abirb\\AppData\\Local\\Temp\\ipykernel_17292\\530657728.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_go_unique.rename(columns={'Entry': 'Protein'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_go = pd.read_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\protein_go_features.csv\")\n",
    "df_go_unique = df_go.drop_duplicates(subset=['Entry'], keep='first')\n",
    "df_go_unique.rename(columns={'Entry': 'Protein'}, inplace=True)\n",
    "\n",
    "df_final_with_go = pd.merge(df_combined, df_go_unique, on='Protein', how='left')\n",
    "\n",
    "df_final_with_go.to_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\final_training_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c05ad",
   "metadata": {},
   "source": [
    "## Adding the Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7367bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2482 total essential genes into a set.\n"
     ]
    }
   ],
   "source": [
    "# Load the Essential Genes List\n",
    "with open('CSEGs_CEGs.txt', 'r') as f:\n",
    "    all_lines = f.readlines()\n",
    "\n",
    "header_line = \"gene\\tessentiality\\tncbi_id\\tensembl\\n\"\n",
    "header_index = -1\n",
    "for i, line in enumerate(all_lines):\n",
    "    if line == header_line:\n",
    "        header_index = i\n",
    "        break\n",
    "\n",
    "# Load the CSV, starting from the header\n",
    "essential_df = pd.read_csv(\n",
    "    'CSEGs_CEGs.txt',\n",
    "    sep='\\t',\n",
    "    skiprows=header_index,\n",
    "    header=0\n",
    ")\n",
    "\n",
    "essential_genes_set = set(essential_df['gene'])\n",
    "print(f\"✅ Loaded {len(essential_genes_set)} total essential genes into a set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dc2776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded main dataset with 20420 rows.\n",
      "Labeling proteins...\n",
      "\n",
      "Labeling complete! Distribution of the new 'TARGET' column:\n",
      "TARGET\n",
      "0    17909\n",
      "1     2511\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Your Main Feature Dataset ---\n",
    "df_main = pd.read_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\final_training_dataset.csv\") \n",
    "print(f\"✅ Loaded main dataset with {len(df_main)} rows.\")\n",
    "\n",
    "\n",
    "def label_essential(gene_names_str):\n",
    "    if not isinstance(gene_names_str, str):\n",
    "        return 0 # Not essential if name is missing\n",
    "    \n",
    "    gene_list = gene_names_str.split()\n",
    "    \n",
    "    # Check if any gene in the list is in our essential set\n",
    "    for gene in gene_list:\n",
    "        if gene in essential_genes_set:\n",
    "            return 1 # It's essential\n",
    "    \n",
    "    return 0 \n",
    "\n",
    "# --- 4. Create the 'TARGET' Column ---\n",
    "print(\"Labeling proteins...\")\n",
    "df_main['TARGET'] = df_main['Gene Names'].apply(label_essential)\n",
    "\n",
    "\n",
    "print(\"\\nLabeling complete! Distribution of the new 'TARGET' column:\")\n",
    "print(df_main['TARGET'].value_counts())\n",
    "\n",
    "df_main.to_csv(\"D:\\\\python_progs\\\\Final_year_proj\\\\Datasets\\\\features_with_target.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
